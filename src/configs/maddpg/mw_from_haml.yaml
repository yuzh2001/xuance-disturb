agent: "MADDPG"
env_name: "MultiWalker"
env_id: "multiwalker_v9"
env_seed: 1
continuous_action: True
learner: "MADDPG_Learner"
policy: "MADDPG_Policy"
representation: "Basic_Identical"
vectorize: "SubprocVecMultiAgentEnv"
runner: "MARL"

on_policy: False
# more
benchmark: True
render: False
distributed_training: False
dl_toolbox: "torch"  # The deep learning toolbox. Choices: "torch", "mindspore", "tensorflow"

# logging
logger: "wandb"  # Choices: "tensorboard", "wandb".
wandb_user_name: "yuzh2001-iscas"
project_name: "XuanCe_Benchmark"

render_mode: 'rgb_array' # Choices: 'human', 'rgb_array'.
fps: 50  # The frames per second for the rendering videos in log file.
test_mode: False  # Whether to run in test mode.
device: "cuda:1"  # Choose an calculating device. PyTorch: "cpu", "cuda:0"; TensorFlow: "cpu"/"CPU", "gpu"/"GPU"; MindSpore: "CPU", "GPU", "Ascend", "Davinci".
master_port: '12355'  # The master port for current experiment when use distributed training.

# environment settings
n_walkers: 3  # walker数量
position_noise: 1e-3  # 位置观测噪声
angle_noise: 1e-3  # 角度观测噪声
forward_reward: 1.0  # 前进奖励系数
terminate_reward: -100.0  # 终止惩罚
fall_reward: -10.0  # 跌倒惩罚
shared_reward: True  # 是否共享奖励
terminate_on_fall: True  # 是否在跌倒时终止
remove_on_fall: False  # 是否在跌倒时移除walker
terrain_length: 200  # 地形长度
max_cycles: 500  # 最大步数

# network architecture
representation_hidden_size: [256, 256]  # the units for each hidden layer
actor_hidden_size: [256, 256]
critic_hidden_size: [512, 512]
activation: 'relu'
activation_action: 'tanh'
use_parameter_sharing: True
use_actions_mask: False


# training parameters
seed: 1  # 随机种子
parallels: 10  # 并行环境数量
buffer_size: 1000000  # 增大buffer size以存储更多经验
batch_size: 1000
learning_rate_actor: 0.0005  # learning rate for actor
learning_rate_critic: 0.001  # learning rate for critic
gamma: 0.99  # discount factor
tau: 0.1  # soft update for target networks

start_noise: 0.1
end_noise: 0.1
sigma: 0.1
start_training: 10000  # start training after n episodes
running_steps: 100000000
train_per_step: True  # True: train model per step; False: train model per episode.
training_frequency: 50

use_grad_clip: True
grad_clip_norm: 0.5

# training and evaluation
eval_interval: 50000  # 评估间隔
test_episode: 10  # 测试轮数

# logging
log_dir: "./logs/maddpg/"  # 日志保存路径
model_dir: "./models/maddpg/"  # 模型保存路径