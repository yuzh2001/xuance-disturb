agent: "MASAC"
continuous_action: True
learner: "MASAC_Learner"
policy: "Gaussian_MASAC_Policy"
representation: "Basic_Identical"
vectorize: "SubprocVecMultiAgentEnv"
runner: "MARL"

# more
benchmark: True
render: False
distributed_training: False
dl_toolbox: "torch"  # The deep learning toolbox. Choices: "torch", "mindspore", "tensorflow"

render_mode: 'rgb_array' # Choices: 'human', 'rgb_array'.
fps: 50  # The frames per second for the rendering videos in log file.
test_mode: False  # Whether to run in test mode.
device: "cuda:0"  # Choose an calculating device. PyTorch: "cpu", "cuda:0"; TensorFlow: "cpu"/"CPU", "gpu"/"GPU"; MindSpore: "CPU", "GPU", "Ascend", "Davinci".
master_port: '12355'  # The master port for current experiment when use distributed training.

# training parameters
seed: 1  # 随机种子
parallels: 16  # 并行环境数量
buffer_size: 1000000  # 增大buffer size以存储更多经验
batch_size: 1024
learning_rate_actor: 0.0005  # learning rate for actor
learning_rate_critic: 0.0005  # learning rate for critic
gamma: 0.99  # discount factor
tau: 0.005  # soft update for target networks
alpha: 0.01
use_automatic_entropy_tuning: True

start_training: 10  # start training after n episodes
running_steps: 15000000
training_frequency: 1
